\section{BACKGROUND \& MOTIVATION}

%Most mobile MR development platforms (i.e. ARCore, and ARKit) utilise a form of \textit{visual odometry} %\cite{yousif2015overview}
%combined with motion or inertial information to map the device's position relative to the real-world, while dedicated HMDs (i.e. HoloLens), leverage multiple cameras with depth sensors to understand the environment and create a virtual 3D map. Once a good mapping has been created, the virtual space (or a coordinate system) is shared with applications to allow synthetic or augmented content to interact with the physical world such as \textit{anchoring} a virtual object on your desk.% This mapping is usually in the form of a 3D \textit{point cloud}.% accompanied by normal vectors to signify orientation of the points which allows for easier surface detection.

% The opening discussion focuses on the necessary processes that delivers the MR services.
AR/MR platforms such as Google ARCore, %\cite{arcore}, 
Apple ARKit, % \cite{arkit}, 
and Windows Mixed Reality API %\cite{windowsMRdev} 
requires spatial understanding of the user environment in order to deliver virtual augmentations that seemingly inhabit the real world, and, in some immersive examples, even interact with physical objects.\footnote{ARKit, \url{https://developer.apple.com/documentation/arkit};
ARCore, \url{https://developers.google.com/ar/};
Windows MR, \url{https://www.microsoft.com/en-au/windows/windows-mixed-reality}. For the rest of the paper, we will be collectively referring to AR and MR as MR.} Fig. \ref{fig:generic-pipeline} presents a generic MR process or information flow diagram. The device captures the spatial information of the space and stores it as a 3D spatial map or point cloud (labelled $S_i$ in Fig. \ref{fig:generic-pipeline}). The point cloud can be accompanied by mesh information to indicate how the points, when connected, represent surfaces and other structures in the user environment. Afterwards, the point cloud is provided to applications to provide spatial understanding and deliver their intended functions, say, augmenting a virtual monster on the floor. However, these 3D point clouds may contain sensitive information which the user did not intend to expose which can, then, be accessed by a potential adversary (labelled $J$ in Fig.\ref{fig:generic-pipeline}), and be further utilized for functionalities beyond the application's intended function such as aggressive localized advertisements. And, so far, there are no mechanisms in place that ensure user data privacy in MR platforms.%Captured visual information are mapped to a digital 3D spatial map with the aid of additional motion and/or depth sensor information. This 3D spatial map is usually stored as a set of 3D points, i.e. $(x, y, z)$, which may be accompanied by additional attributes such as orientation (i.e. normal vectors) or photometric information (e.g. RGB, SIFT feature vector, etc.).  further accompanied by a mesh information that tells which points, when connected, form surfaces.
%However, even with only the 3D point information left -- even without additional attributes -- much of the objects within the space or the space itself can still be identified.

\begin{figure}[t]
	\centering
	\vspace{2mm}
	\begin{subfigure}{\columnwidth}
		\includegraphics[width=\columnwidth]{figures/adversary-model-pipeline-v6-revised-a.pdf}
		\caption{\footnotesize Information flow diagram (following the green solid arrows) for an intended MR function $G$, with an attacker $J$ which can perform adversarial spatial inference: (1) adversarial inference \textit{modeling} or \textit{learning} from, say, historical 3D data, and (2) adversarial inference or \textit{matching} over currently released 3D data}
		\label{fig:generic-pipeline}
    	\vspace{3mm}
	\end{subfigure}
	\begin{subfigure}{\columnwidth}
		\includegraphics[width=\columnwidth]{figures/adversary-model-pipeline-v6-revised-b.pdf}
		\caption{\footnotesize Inserting an intermediate privacy-preserving mechanism $M$ which aims to prevent spatial inference}
		\label{fig:with-privacy-mechanism}
	\end{subfigure}
	\vspace{-3mm}
    \caption{\small AR/MR pipeline diagrams with (a) an attacker, and (b) an introduced intermediary privacy mechanism.}
	\label{fig:adversary-model-pipeline}
	\vspace{-5mm}
\end{figure}

%\textbf{Why 3D?} 
%Furthermore, despite 3D data being a structural representation of the real world, 3D data is perceptually latent from the users. With images and video, what the ``machine sees'' is what the ``user sees'' and a great deal of privacy work have been done on these data forms. Contrariwise, in MR, the experience is exported as visual data (e.g. objects augmented on the user's view) while the underlying spatial mapping, and its extent, as well as the density of the captured points, is not exposed to the users: what the machine sees is different--arguably, even more--than what the user sees. That is, the digital representation of the physical world is not exposed to the user and that the user is oblivious about the captured spatial mapping data. This inherent perceptual difference creates a latency from user perception and, perhaps, affects--or the lack thereof--how users perceive the sensitivity of 3D information.

Aside from the the spatial structural information, the mapping can also include 3D maps of objects within the space. It can also reveal the location of the user: the general location as well as the user's location within the space. Similarly, most users are oblivious about the various information that are included in the spatial maps captured and stored by MR platforms.

%\section{Related Work}\label{sec:related-work}

As majority of the work on MR have been focused on delivering the technology, only recently have there been efforts in addressing the security, safety, and privacy risks associated with MR technology. Thus, it is important to start designing and developing \textit{privacy-enhancing technologies} (PETs) especially those that can be applied to the MR use case. Several MR-related PETs that have been proposed in the literature--primarily utilizing \textit{sanitization} and information \textit{abstraction}--are listed in \cite{deguzman2018security}. %To maintain and control the utility of information, 

%\paragraph{Approaches to visual data protection}\label{rrw:vision} Most of the earlier PETs for MR were primarily focused on \textit{visual} information (i.e. image and video) \textit{sanitization} \cite{jana2013scanner,raval2014markit, roesner2014world, aditya2016pic, raval2016you, shu2016cardea, li2016privacycamera, zarepour2016context, steilPrivaceye2018}. Aside from these are \textit{abstraction} approaches to privacy protection \cite{jana2013enabling, figueiredo2016prepose} using the idea of \textit{least privilege} \cite{vilk2014least,vilk2015surroundweb}. A very recent work also utilized the idea of least privilege to apply visual abstractions for mobile MR \cite{deguzman2019safeMR}. However, most of these abstraction approaches are only targeted over specific input types such as physiometric information (i.e. faces, user gestures, and so on), and have not specifically provided protection against spatial recognition attacks. On the other hand, all the sanitization approaches are all focused on post-captured images which can still pose security and privacy risks; moreover, they have only been applied on the wide use case of visual capture devices and not on the specific MR use case.

\subsubsection*{Related Work}%Approaches to 3D data protection}\label{rrw:3d}
Two works have started to look into and expose the actual risks brought about by unprotected and indefinite access to 3D data by MR applications. Using machine learning, original scenes can be revealed from structure from motion (SfM) 3D point cloud data with additional sparse SIFT or other photometric information \cite{pittaluga2019revealing}. A concurrent work focused on presenting a privacy-preserving method of pose estimation to counter these risks. It removes the necessity for 3D point cloud data by instead using 3D line cloud--effectively obfuscating 3D structural, i.e. geometrical, information--during pose estimation \cite{speciale2019privacy}; however, the 3D line cloud approach only addresses the pose estimation functionality and does not present the viability of its usability for surface or object detection which is necessary for a virtual object to be rendered or ``anchored'' onto. Thus, it would still be necessary for 3D point cloud data to be exposed but, perhaps, with some privacy-preserving transformations to hide sensitive content and further prevent spatial recognition. %Furthermore, even with the absence of additional photometric information, spatial location of 3D point cloud data can still be recognized given that adversaries have access to an ensemble of historical 3D point cloud data \cite{deguzman2019firstlook}. 

\section{3D spatial privacy}

\begin{figure}[t]
	\centering
	\vspace{-2mm}
	\begin{subfigure}{0.61\columnwidth}
		\includegraphics[width=\columnwidth]{figures/cdng-successive-interspace.pdf}
		\vspace{-5mm}
		\caption{\footnotesize Inter-space error rate\newline }
		\label{fig:successive-interspace}
    	%\vspace{3mm}
	\end{subfigure}
	\begin{subfigure}{0.37\columnwidth}
		\includegraphics[width=\columnwidth]{figures/cdng-successive-intraspace.pdf}
		\vspace{-5mm}
        \caption{\footnotesize Intra-space distance error}
		\label{fig:successive-intraspace}
	\end{subfigure}
	\vspace{-3mm}
    \caption{\small Adversarial inference performance as we \textbf{release} more of the space}
	\label{fig:successive-performance}
	\vspace{-5mm}
\end{figure}

Our earlier work provided preliminary evidence of how easy it is for an adversary to infer the location of spaces from captured 3D data \cite{deguzman2019firstlook}. And how, even with spatial generalization (i.e. the 3D space is generalized in to a set of planes), spatial inference is still possible at a significant success rate, i.e. $P_{success}\geq0.2$ for spaces with radius $r\geq 0.5$meters. We have extended this work with an improved attacker that not only \textit{recognizes} the space, i.e. \textit{inter}-space inference, but also infers the user's location \textit{within} the space, i.e. \textit{intra}-space inference. %To construct the attacker, we build up on existing place recognition methods that have been applied on 3D lidar data and modify it to be usable for the scale on which 3D data is captured by MR platforms. Then, we present spatial generalizations with conservative releasing as a privacy approach. %We also utilize an extended dataset that includes various indoor and outdoor scenes.

%\begin{figure}[t]
%	\centering
	%\vspace{2mm}
%	\begin{subfigure}{0.48\columnwidth}
%		\includegraphics[width=\columnwidth]{figures/cdng-partial-interspace.pdf}
%		\vspace{-5mm}
%		\caption{\small Inter-space error rate}
%		\label{fig:partial-interspace}
    	%\vspace{3mm}
%	\end{subfigure}
%	\begin{subfigure}{0.48\columnwidth}
%		\includegraphics[width=\columnwidth]{figures/cdng-partial-intraspace.pdf}
%		\vspace{-5mm}
 %       \caption{\small Intra-space distance error}
%		\label{fig:partial-intraspace}
%	\end{subfigure}
%	\vspace{-3mm}
 %   \caption{\small Adversarial inference performance as we vary the size of the revealed space}
%	\label{fig:partial-performance}
%	\vspace{-3mm}
%\end{figure}

We measure the privacy of the released point cloud in terms of the performance on these two levels of inference. For inter-space inference, we use the inference error rate directly, while, for intra-space inference, we use the distance error from the true position of the released space. Fig. \ref{fig:successive-performance} shows inference performance in terms if these measures as we reveal more of the space--emulating the case when the user moves around revealing more of the space that they are in. Fig. \ref{fig:successive-interspace} shows that even at small radius of $r = 0.5$m, $P_{error}\leq0.5$ after 30 releases. And the intra-space distance error, as shown in Fig. \ref{fig:successive-intraspace}, quickly drops and flattens around $3$m after 5 releases or more. Thus, \textit{na\"ive} generalizations are not enough protection from these spatial inference attacks.

\begin{figure}[t]
	\vspace{-2mm}
    \begin{subfigure}{0.49\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/successive-varying-planes-heatmap-quantized-r05-3.png}
		\vspace{-5mm}
        \caption{\footnotesize $r = 0.5$m}
		\label{fig:varying-planes-heatmap}
	\end{subfigure}
%	\vspace{-2mm}
    \begin{subfigure}[]{0.49\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/successive-varying-planes-heatmap-quantized-r10-3.png}
		\vspace{-5mm}
		\caption{\footnotesize $r = 1.0$m }
		\label{fig:varying-planes-heatmap-r1}
	\end{subfigure}
	%\vspace{-3mm}
	\caption{\small Quantized heatmap of average inter-space privacy of conservatively released planes over successive releasing}
	\label{fig:conservative-releasing-inter}
	\vspace{-5mm}
\end{figure}

\subsubsection*{Conservatively releasing generalized planes} 
Therefore, it is necessary to provide users with a form of protection, i.e. privacy preserving 3D point cloud releasing. We demonstrate that we can enhance the protection from plane generalizations by simply conservatively releasing the generalized planes. As shown in Fig. \ref{fig:conservative-releasing-inter}, our preliminary investigation shows that we can reveal at most 13 planes and avoid inter-space inference almost half the time.\footnote{Fig. \ref{fig:conservative-releasing-inter} shows a quantized heatmap of average inter-space privacy values for easy visualization. The quantized values as shown in the colorbar are $\{[0,0.5),[0.5,0.75),[0.75,1.0]\}$.} Specifically, with such very conservative releases, the success rate of an (inter-space) inferrer is no better than a random guess. And, for the occasions that the adversary correctly recognizes the space, the intra-space location can be off by at least 3 meters. %Moreover, we have shown a quantification of how much we can improve both $\Pi_1$ and $\Pi_2$ by reducing the size of the partial spaces to be revealed. Consequently, in terms of data utility $Q$, a smaller size is anyway preferred to provide good (i.e. low) $Q$. %Similarly, for intra-space inference, for those correctly ``guessed'' spaces will be off by 5 meters or farther.

Overall, these results provides quantities, i.e. thresholds, that allows us to potentially protect users and their spaces as they use MR services. And, so far, we have only utilized simple approaches to spatial privacy protection. Generalization are already implemented in most MR platforms. Thus, what remains is the implementation of conservative plane releasing to provide protection and insert it as in intermediary form of protection, $M$, as shown in Fig. \ref{fig:with-privacy-mechanism}.
%For future work, a practical investigation can provide us with the impact of our presented simple approach on usability of the MR application provided with such generalizations. Furthermore, we also plan to investigate the effectiveness and impact of adding plane perturbations, i.e. translation and/or rotation. %Future work, 1) perturbations, i.e. plane translation and/or rotation; 2) practically demonstrate a proof-of-concept using at least an HMD and a mobile device, then, measure QoE. A practical investigation can provide us with actual user feedback on whether our approach affects the usability of the application or not.
